{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eqUx_Zamiha"
      },
      "outputs": [],
      "source": [
        "# REFERNCE & DEBUG: CHATGPT\n",
        "# Author: Roy Li(Primary), ChatGPT 4.0(Support)\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.algorithms.community import girvan_newman\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "csv_file_path = '/content/ProcessedFalseScaled.csv'\n",
        "\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "G_false = nx.Graph()\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    G_false.add_edge(row['Source'], row['Target'], weight=row['Weight'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL5_Xx-QqfHq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "csv_file_path = '/content/ProcessedTrueScaled.csv'\n",
        "\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "G_true = nx.Graph()\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    G_true.add_edge(row['Source'], row['Target'], weight=row['Weight'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B95OvvDjwoTb",
        "outputId": "f66f06a6-1329-4e7f-cf5f-f7cb4c55fac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2614\n",
            "2425\n",
            "3354\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "all_nodes_false = list(G_false.nodes)\n",
        "print(len(all_nodes_false))\n",
        "all_nodes_true = list(G_true.nodes)\n",
        "print(len(all_nodes_true))\n",
        "\n",
        "merged_nodes = list(set(all_nodes_false + all_nodes_true))\n",
        "\n",
        "print(len(merged_nodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7KIEMAJDUKw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "csv_file_path_false = '/content/ProcessedFalseScaled.csv'\n",
        "csv_file_path_true = '/content/ProcessedTrueScaled.csv'\n",
        "\n",
        "df_false = pd.read_csv(csv_file_path_false)\n",
        "df_true = pd.read_csv(csv_file_path_true)\n",
        "\n",
        "G_initial = nx.Graph()\n",
        "\n",
        "for index, row in df_false.iterrows():\n",
        "    G_initial.add_edge(row['Source'], row['Target'], weight=row['Weight'])\n",
        "\n",
        "for index, row in df_true.iterrows():\n",
        "    G_initial.add_edge(row['Source'], row['Target'], weight=row['Weight'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ya6Asie01gAM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "csv_file_path_false = '/content/ProcessedFalseScaled.csv'\n",
        "csv_file_path_true = '/content/ProcessedTrueScaled.csv'\n",
        "\n",
        "df_false = pd.read_csv(csv_file_path_false)\n",
        "df_true = pd.read_csv(csv_file_path_true)\n",
        "\n",
        "G_initial_step2 = nx.Graph()\n",
        "\n",
        "for index, row in df_false.iterrows():\n",
        "    G_initial_step2.add_edge(row['Source'], row['Target'], weight=row['Co_Occurrence'])\n",
        "\n",
        "for index, row in df_true.iterrows():\n",
        "    G_initial_step2.add_edge(row['Source'], row['Target'], weight=row['Co_Occurrence'])\n",
        "\n",
        "for node in G_initial_step2.nodes():\n",
        "    if node in G_false and node in G_true:\n",
        "        G_initial_step2.nodes[node]['truth'] = 'mix'\n",
        "    elif node in G_false:\n",
        "        G_initial_step2.nodes[node]['truth'] = 'false'\n",
        "    elif node in G_true:\n",
        "        G_initial_step2.nodes[node]['truth'] = 'true'\n",
        "    else:\n",
        "        G_initial_step2.nodes[node]['truth'] = 'unknown'\n",
        "\n",
        "\n",
        "betweenness_false = nx.betweenness_centrality(G_false)\n",
        "betweenness_true = nx.betweenness_centrality(G_true)\n",
        "\n",
        "for node, data in G_initial_step2.nodes(data=True):\n",
        "    if data['truth'] == 'mix':\n",
        "        betweenness_score_false = betweenness_false.get(node, 0) \n",
        "        betweenness_score_true = betweenness_true.get(node, 0)\n",
        "\n",
        "        if betweenness_score_false > betweenness_score_true:\n",
        "            G_initial_step2.nodes[node]['truth'] = 'false'\n",
        "        elif betweenness_score_true > betweenness_score_false:\n",
        "            G_initial_step2.nodes[node]['truth'] = 'true'\n",
        "\n",
        "\n",
        "gml_file_path = 'G_initial_step3.gml'\n",
        "nx.write_gml(G_initial_step2, gml_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqRuqCy3R5fZ"
      },
      "outputs": [],
      "source": [
        "import community.community_louvain\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "gml_file_path = '/content/G_initial_step3.gml'\n",
        "G = nx.read_gml(gml_file_path)\n",
        "\n",
        "partition = community.community_louvain.best_partition(G)\n",
        "\n",
        "community_sizes = Counter(partition.values())\n",
        "\n",
        "modularity_score = community.community_louvain.modularity(partition, G)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rytVeRE1TbD8"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import community.community_louvain as community_louvain\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "gml_file_path = '/content/G_initial_step3.gml'\n",
        "G = nx.read_gml(gml_file_path)\n",
        "\n",
        "partition = community.community_louvain.best_partition(G)\n",
        "\n",
        "\n",
        "community_to_nodes = defaultdict(list)\n",
        "for node, comm in partition.items():\n",
        "    community_to_nodes[comm].append(node)\n",
        "\n",
        "\n",
        "results = defaultdict(dict)\n",
        "\n",
        "for comm, nodes in community_to_nodes.items():\n",
        "    for node_type in ['true', 'false']:\n",
        "        type_nodes = [n for n in nodes if G.nodes[n].get('truth') == node_type]\n",
        "        subG = G.subgraph(type_nodes)\n",
        "\n",
        "        if len(subG) == 0:\n",
        "            continue\n",
        "\n",
        "        clustering_coeff = nx.average_clustering(subG)\n",
        "\n",
        "        if nx.is_connected(subG):\n",
        "            avg_shortest_path_length = nx.average_shortest_path_length(subG)\n",
        "        else:\n",
        "            largest_cc = max(nx.connected_components(subG), key=len)\n",
        "            largest_subG = subG.subgraph(largest_cc)\n",
        "            avg_shortest_path_length = nx.average_shortest_path_length(largest_subG)\n",
        "\n",
        "        results[comm][f'{node_type}_clustering_coeff'] = clustering_coeff\n",
        "        results[comm][f'{node_type}_avg_shortest_path_length'] = avg_shortest_path_length\n",
        "\n",
        "for comm, metrics in results.items():\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"  {metric}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dNfS0Z-xXN18",
        "outputId": "83e2c93e-0ca5-49c5-bab7-2e6bc52212fc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "communities = list(results.keys())\n",
        "\n",
        "communities = [comm for comm in communities if 'true_clustering_coeff' in results[comm]]\n",
        "\n",
        "\n",
        "true_clustering_coeffs = [results[comm]['true_clustering_coeff'] for comm in communities]\n",
        "false_clustering_coeffs = [results[comm]['false_clustering_coeff'] for comm in communities]\n",
        "true_avg_shortest_paths = [results[comm]['true_avg_shortest_path_length'] for comm in communities]\n",
        "false_avg_shortest_paths = [results[comm]['false_avg_shortest_path_length'] for comm in communities]\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(communities))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(index, true_clustering_coeffs, bar_width, label='True Clustering Coeff', color = 'skyblue')\n",
        "plt.bar(index + bar_width, false_clustering_coeffs, bar_width, label='False Clustering Coeff', color = 'salmon')\n",
        "\n",
        "plt.xlabel('Community')\n",
        "plt.ylabel('Average Clustering Coefficient')\n",
        "plt.xticks(index + bar_width / 2, communities)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('coef.png')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(index, true_avg_shortest_paths, bar_width, label='True Avg Shortest Path Length', color = 'skyblue')\n",
        "plt.bar(index + bar_width, false_avg_shortest_paths, bar_width, label='False Avg Shortest Path Length', color = 'salmon')\n",
        "\n",
        "plt.xlabel('Community')\n",
        "plt.ylabel('Average Shortest Path Length')\n",
        "plt.xticks(index + bar_width / 2, communities)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('short.png')\n",
        "# plt.close()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
